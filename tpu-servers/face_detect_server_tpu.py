"""
Detect and recognize faces using Google edge tpu served by zerorpc

Should be called from a zerorpc client with ZoneMinder
alarm image metadata from zm-s3-upload.js.

This is part of the smart-zoneminder project.
See https://github.com/goruck/smart-zoneminder

Copyright (c) 2018, 2019 Lindo St. Angel
"""

import numpy as np
import json
import zerorpc
import pickle
import cv2
import logging
from edgetpu.detection.engine import DetectionEngine

logging.basicConfig(level=logging.ERROR)

# Get configuration.
with open('./config.json') as fp:
    config = json.load(fp)['faceDetServer']

# Tensorflow face detection file system path.
PATH_TO_FACE_DET_MODEL = config['faceDetModelPath']

# py torch face embeddings model path. 
PATH_TO_FACE_EMB_MODEL = config['faceEmbModelPath']

# Heartbeat interval for zerorpc client in ms.
# This must match the zerorpc client config. 
ZRPC_HEARTBEAT = config['zerorpcHeartBeat']

# IPC (or TCP) socket for zerorpc.
# This must match the zerorpc client config.
ZRPC_PIPE = config['zerorpcPipe']

# Mount point of zm alarms on local tpu machine. 
MOUNT_POINT = config['mountPoint']

# Settings for SVM face classifier.
# The model and label encoder needs to be generated by 'train.py' first. 
SVM_MODEL_PATH = config['svmModelPath']
SVM_LABEL_PATH = config['svmLabelPath']
MIN_SVM_PROBA = config['minSvmProba']

# Images with Variance of Laplacian less than this are declared blurry. 
FOCUS_MEASURE_THRESHOLD = config['focusMeasureThreshold']

# Initialize tpu engine.
face_engine = DetectionEngine(PATH_TO_FACE_DET_MODEL)

# Initialize face embeddings model.
embedder = cv2.dnn.readNetFromTorch(PATH_TO_FACE_EMB_MODEL)

# Load svm face recognition model along with the label encoder.
with open(SVM_MODEL_PATH, 'rb') as fp:
	recognizer = pickle.load(fp)
with open(SVM_LABEL_PATH, 'rb') as fp:
	le = pickle.load(fp)

def svm_face_classifier(encoding, min_proba):
	# perform svm classification to recognize the face based on 128D encoding
	# note: reshape(1,-1) converts 1D array into 2D
	preds = recognizer.predict_proba(encoding.reshape(1, -1))[0]
	j = np.argmax(preds)
	proba = preds[j]
	logging.debug('svm proba {} name {}'.format(proba, le.classes_[j]))
	if proba >= min_proba:
		name = le.classes_[j]
		logging.info('svm says this is {}'.format(name))
	else:
		name = None # prob too low to recog face
		logging.info('svm cannot recognize face')
	return name

def variance_of_laplacian(image):
	# compute the Laplacian of the image and then return the focus
	# measure, which is simply the variance of the Laplacian
	return cv2.Laplacian(image, cv2.CV_64F).var()

# zerorpc server.
class DetectRPC(object):
    def detect_faces(self, test_image_paths):
        # List that will hold all images with any face detection information. 
        objects_detected_faces = []

        # Loop over the images paths provided. 
        for obj in test_image_paths:
            logging.info('**********Find Face(s) for {}'.format(obj['image']))
            for label in obj['labels']:
                # If the object detected is a person then try to identify face. 
                if label['name'] == 'person':
                    # Read image from disk. 
                    img = cv2.imread(MOUNT_POINT + obj['image'])
                    if img is None:
                        # Bad image was read.
                        logging.error('Bad image was read.')
                        label['face'] = None
                        continue

			        # First bound the roi using the coord info passed in.
			        # The roi is area around person(s) detected in image.
			        # (x1, y1) are the top left roi coordinates.
			        # (x2, y2) are the bottom right roi coordinates.
                    y2 = int(label['box']['ymin'])
                    x1 = int(label['box']['xmin'])
                    y1 = int(label['box']['ymax'])
                    x2 = int(label['box']['xmax'])
                    roi = img[y2:y1, x1:x2, :]
                    #cv2.imwrite('./roi.jpg', roi)
                    if roi.size == 0:
                        # Bad object roi...move on to next image.
                        logging.error('Bad object roi.')
                        label['face'] = None
                        continue

                    # Need roi shape for later conversion of face coords.
                    (h, w) = roi.shape[:2]
                    # Resize roi for face detection.
                    # The tpu face det requires (320, 320).
                    res = cv2.resize(roi, dsize=(320, 320), interpolation=cv2.INTER_AREA)
                    #cv2.imwrite('./res.jpg', res)

			        # Detect the (x, y)-coordinates of the bounding boxes corresponding
			        # to each face in the input image using the TPU engine.
                    # NB: reshape(-1) converts the np img array into 1-d. 
                    detection = face_engine.DetectWithInputTensor(res.reshape(-1),
                        threshold=0.1, top_k=3)
                    if not detection:
                        # No face detected...move on to next image.
                        logging.info('No face detected.')
                        label['face'] = None
                        continue

			        # Convert coords and carve out face roi.
                    box = (detection[0].bounding_box.flatten().tolist()) * np.array([w, h, w, h])
                    (face_left, face_top, face_right, face_bottom) = box.astype('int')
                    face_roi = roi[face_top:face_bottom, face_left:face_right, :]
                    #cv2.imwrite('./face_roi.jpg', face_roi)

			        # Compute the focus measure of the face
			        # using the Variance of Laplacian method.
			        # See https://www.pyimagesearch.com/2015/09/07/blur-detection-with-opencv/
                    gray = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)
                    fm = variance_of_laplacian(gray)

			        # If fm below a threshold then face probably isn't clear enough
			        # for face recognition to work, so skip it. 
                    if fm < FOCUS_MEASURE_THRESHOLD:
                        logging.info('Face too blurry to recognize.')
                        name = None
                    else:
                        # Find the 128-dimension face encoding for face in image.
                        # Construct a blob for the face roi, then pass the blob
                        # through the face embedding model to obtain the 128-d
                        # quantification of the face.
                        face_blob = cv2.dnn.blobFromImage(face_roi, 1.0 / 255, (96, 96),
                            (0, 0, 0), swapRB=True, crop=False)
                        embedder.setInput(face_blob)
                        encoding = embedder.forward()[0]
					    # Perform svm classification on the encodings to recognize the face.
                        name = svm_face_classifier(encoding, MIN_SVM_PROBA)

			        # Add face name to label metadata.
                    label['face'] = name

	        # Add processed image to output list. 
            objects_detected_faces.append(obj)

        # Convert json to string and return data. 
        return(json.dumps(objects_detected_faces))

s = zerorpc.Server(DetectRPC(), heartbeat=ZRPC_HEARTBEAT)
s.bind(ZRPC_PIPE)
s.run()